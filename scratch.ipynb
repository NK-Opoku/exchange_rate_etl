{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x784c3e1e9940; dsn: 'user=admin password=xxx dbname=dev host=coinbase-cluster.ctpfzvbnyqdb.us-east-1.redshift.amazonaws.com port=5439', closed: 0>\n",
      "Connection to Postgres Server: coinbase-cluster.ctpfzvbnyqdb.us-east-1.redshift.amazonaws.com is successful on Port: 5439. Database is dev\n",
      "Connection to Postgres Server: 172.17.0.2 is successful on Port: 5432. Database is coinbase10\n",
      "<connection object at 0x784c3cac2d40; dsn: 'user=admin password=xxx dbname=dev host=coinbase-cluster.ctpfzvbnyqdb.us-east-1.redshift.amazonaws.com port=5439', closed: 0>\n",
      "Connection to Postgres Server: coinbase-cluster.ctpfzvbnyqdb.us-east-1.redshift.amazonaws.com is successful on Port: 5439. Database is dev\n",
      "Connection to Postgres Server: 172.17.0.2 is successful on Port: 5432. Database is coinbase10\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd \n",
    "from importlib import reload \n",
    "import gzip \n",
    "import connection\n",
    "\n",
    "\n",
    "connection = reload(connection) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x784c3cac2ac0; dsn: 'user=postgres password=xxx dbname=coinbase10 host=172.17.0.2 port=5432', closed: 0>\n",
      "\n",
      "\n",
      "<built-in method cursor of psycopg2.extensions.connection object at 0x784c3cac2ac0>\n"
     ]
    }
   ],
   "source": [
    "# create connection object postgres db \n",
    "local_con =connection.local_pgcon\n",
    "local_cur = connection.local_pgcur\n",
    "\n",
    "print(local_con) \n",
    "print(\"\\n\")\n",
    "print(local_cur) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method cursor of psycopg2.extensions.connection object at 0x784c3e1e9940>\n"
     ]
    }
   ],
   "source": [
    "# create s3 object\n",
    "s3 = connection.s3_bucket\n",
    "\n",
    "# create Redshift connection and cursor\n",
    "cur_redshift = connection.redshift_cur\n",
    "conn_redshift = connection.redshift_con\n",
    "# print(cur_redshift)\n",
    "print(cur_redshift)\n",
    "\n",
    "#create local postgres connection and cursor\n",
    "cur_pg = connection.local_pgcur\n",
    "conn_pg = connection.local_pgcon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this block\n",
    "# conn_redshift = connection.conn_redshift\n",
    "# cur_redshift = connection.cur_redshift\n",
    "# print(cur_redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 ='https://api.binance.com/api/v3/ticker/price'\n",
    "\n",
    "url = 'https://api.coinbase.com/v2/currencies'\n",
    "response = requests.get(url2)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully: saturday_rate.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "\n",
    "    api_data = response.text\n",
    "   \n",
    "    api_data = json.loads(api_data)\n",
    "        # use this code if the result of the parsed json is in the form {data: {all the response data}}\n",
    "    # api_data = api_data.get('data', [])\n",
    "\n",
    "    # Read the JSON data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(api_data)\n",
    "    \n",
    "    # Specify the file path where you want to save the CSV file\n",
    "    csv_file_path = 'saturday_rate.csv'\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    print(\"CSV file saved successfully:\", csv_file_path)\n",
    "else:\n",
    "    print(\"Failed to retrieve data. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saturday_rate.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# creating a filename variable for compressed file to be uploaded to S3\n",
    "file_name = csv_file_path + '.gz'\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df to zip\n",
    "\n",
    "df.to_csv(file_name, index=False, compression='gzip')\n",
    "\n",
    "compressed_csv = file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(compressed_csv, 'rb') as file:\n",
    "    # Upload the file object to S3 bucket\n",
    "    s3.upload_fileobj(file, 'emil-coinbase-bucket', compressed_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file uploaded to S3 bucket successfully\n"
     ]
    }
   ],
   "source": [
    "# Check if the file has been successfully uploaded\n",
    "if s3.head_object(Bucket='emil-coinbase-bucket', Key=compressed_csv):\n",
    "    print(\"CSV file uploaded to S3 bucket successfully\")\n",
    "else:\n",
    "    print(\"Upload not successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # create table for local db\n",
    "table_name = 'currency_saturday'\n",
    "rates_table = f'''CREATE TABLE IF NOT EXISTS {table_name} (ID VARCHAR(3) PRIMARY KEY, Name VARCHAR(65), min_size numeric(10, 8) ) '''\n",
    "connection.cur_pg.execute(rates_table)\n",
    "connection.conn_pg.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT DATA TO LOCAL DB\n",
    "try:\n",
    "    # size of each batch\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Insert DataFrame into database in batches\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i + batch_size]\n",
    "        values = [tuple(row) for row in batch_df.values]\n",
    "\n",
    "        placeholders = ','.join(['%s'] * len(df.columns))\n",
    "        try:\n",
    "            insert_query = f\"INSERT INTO {table_name} (ID, Name, min_size) VALUES ({placeholders})\"\n",
    "            connection.cur_pg.executemany(insert_query, values)\n",
    "            connection.conn_pg.commit()\n",
    "\n",
    "            print(insert_query)\n",
    "        except Exception as e:\n",
    "            # Rollback the transaction\n",
    "            connection.conn_pg.rollback()\n",
    "\n",
    "            # If the insert fails due to a unique constraint violation, perform an update instead\n",
    "            if 'duplicate key' in str(e):\n",
    "                for value in values:\n",
    "                    update_query = \"UPDATE currency_rates SET Name = %s, min_size = %s WHERE ID = %s\"\n",
    "                    connection.cur_pg.execute(update_query, (value[1], value[2], value[0]))\n",
    "                    connection.conn_pg.commit()  # Commit each update\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during batch data insertion:\", e)\n",
    "    connection.conn_pg.rollback()  # Rollback the transaction in case of an error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT INTO users (id, rate)\n",
    "# VALUES (1, 0)\n",
    "# ON CONFLICT (id) DO UPDATE\n",
    "# SET min_value = %s;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedFile",
     "evalue": "could not open file \"./scratch_csv.csv\" for reading: No such file or directory\nHINT:  COPY FROM instructs the PostgreSQL server process to read a file. You may want a client-side facility such as psql's \\copy.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedFile\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10400\\1509245355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# DELIMITER ','; \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcur_pg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsert_from_local\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mconn_pg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUndefinedFile\u001b[0m: could not open file \"./scratch_csv.csv\" for reading: No such file or directory\nHINT:  COPY FROM instructs the PostgreSQL server process to read a file. You may want a client-side facility such as psql's \\copy.\n"
     ]
    }
   ],
   "source": [
    "# Upload data to local postgres db \n",
    "    # create table\n",
    "table_name = 'currency_rates'\n",
    "rates_table = f'''CREATE TABLE IF NOT EXISTS {table_name} (ID VARCHAR(3), Name VARCHAR(65), min_size numeric(10, 8) ) '''\n",
    "cur_pg.execute(rates_table)\n",
    "conn_pg.commit()\n",
    "    # copy csv\n",
    "\n",
    "\n",
    "# insert_from_local = f\"\"\"COPY currency_rates\n",
    "# FROM '{csv_file_path}'\n",
    "# DELIMITER ','\n",
    "# CSV\n",
    "# HEADER;\n",
    "#  \"\"\"\n",
    "\n",
    "insert_from_local= f\"\"\"copy currency_rates FROM '{csv_file_path}' CSV HEADER DELIMITER ','; \"\"\"\n",
    "\n",
    "\n",
    "# insert_from_local = f\"\"\"COPY currency_rates\n",
    "# FROM '{csv_file_path}'\n",
    "# IGNOREHEADER 1\n",
    "# FORMAT AS csv\n",
    "# DELIMITER ','; \"\"\"\n",
    "\n",
    "cur_pg.execute(insert_from_local)\n",
    "conn_pg.commit()\n",
    "\n",
    "conn_pg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  delete this block\n",
    "connection.cur_redshift.execute('ROLLBACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # create table REDSHIFT\n",
    "\n",
    "\n",
    "try:\n",
    "    table_name = 'currency_rates'\n",
    "    rates_table = f'''CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                        ID VARCHAR(3) PRIMARY KEY, \n",
    "                        Name VARCHAR(65), \n",
    "                        min_size numeric(10, 8)\n",
    "                    )'''\n",
    "    \n",
    "  \n",
    "    connection.cur_redshift.execute(rates_table)\n",
    "    connection.conn_redshift.commit()\n",
    "    print(\"Table created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    connection.conn_redshift.rollback()\n",
    "    print(f\"Error creating table: {e}\")\n",
    "\n",
    "finally:\n",
    "    connection.cur_redshift.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO currency_rates (ID, Name, min_size) VALUES (%s,%s,%s)\n"
     ]
    }
   ],
   "source": [
    "# upload data to Redshift\n",
    "    # create table\n",
    "table_name = 'currency_rates'\n",
    "rates_table = f'''CREATE TABLE IF NOT EXISTS {table_name} (ID VARCHAR(3) PRIMARY KEY, Name VARCHAR(65), min_size numeric(10, 8) ) '''\n",
    "connection.cur_redshift.execute(rates_table)\n",
    "connection.conn_redshift.commit()\n",
    "    # copy csv\n",
    "\n",
    "\n",
    "try:\n",
    "    # Define the size of each batch\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Insert DataFrame into Redshift database in batches\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        values = [tuple(row) for row in batch_df.values]\n",
    "\n",
    "        placeholders = ','.join(['%s'] * len(df.columns))\n",
    "        # # column_names = ','.join(df.columns)\n",
    "        # column_names = ', '.join([f\"{re.sub('[^a-zA-Z]+', '', col.replace(' ', '_'))}\" for col in df.columns])\n",
    "        insert_query = f\"INSERT INTO currency_rates (ID, Name, min_size) VALUES ({placeholders})\"\n",
    "        print(insert_query)\n",
    "        connection.cur_redshift.executemany(insert_query, values)\n",
    "        connection.conn_redshift.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during batch data insertion:\", e)\n",
    "    connection.conn_redshift.rollback()  # Rollback the transaction in case of an error\n",
    "\n",
    "aws_access_key_id = connection.aws_access_key_id\n",
    "aws_secret_access_key = connection.aws_secret_access_key\n",
    "\n",
    "# insert_from_s3 = f\"\"\"COPY currency_rates\n",
    "# FROM 's3://emil-coinbase-bucket/{csv_file_path}'\n",
    "# CREDENTIALS 'aws_access_key_id={aws_access_key_id};aws_secret_access_key={aws_secret_access_key}'\n",
    "# IGNOREHEADER 1\n",
    "# FORMAT AS csv\n",
    "# gzip\n",
    "# DELIMITER ','; \"\"\"\n",
    "\n",
    "# insert_from_s3 = f\"\"\"COPY currency_rates\n",
    "# FROM './{csv_file_path}'\n",
    "# CREDENTIALS 'admin;Hello123'\n",
    "# IGNOREHEADER 1\n",
    "# FORMAT AS csv\n",
    "# DELIMITER ','; \"\"\"\n",
    "\n",
    "# connection.cur_redshift.execute(insert_from_s3)\n",
    "# connection.conn_redshift.commit()\n",
    "\n",
    "# conn_redshift.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x000002543DE7EA68; dsn: 'user=admin password=xxx dbname=dev host=coinbase-cluster.ctpfzvbnyqdb.us-east-1.redshift.amazonaws.com port=5439', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "conn_redshift = connection.conn_redshift\n",
    "cur_redshift = connection.cur_redshift\n",
    "print(conn_redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_redshift.execute('ROLLBACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
